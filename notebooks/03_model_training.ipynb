{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\PMLS\\\\Desktop\\\\Jupyter notebook\\\\Campusx Codes\\\\Deep-Learning-Project\\\\cnnclassifier\\\\notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\PMLS\\\\Desktop\\\\Jupyter notebook\\\\Campusx Codes\\\\Deep-Learning-Project\\\\cnnclassifier'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Update config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "training:\n",
    "  root_dir: models/training\n",
    "  trained_model_path: models/training/model.h5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Update params.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Update src/constant/\\_\\_init\\_\\_.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Update the entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    trained_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    training_data: Path\n",
    "    params_augmentation: bool\n",
    "    params_image_size: list\n",
    "    params_batch_size: int\n",
    "    params_epochs: int\n",
    "    params_learning_rate: float\n",
    "    params_activation: str\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Update the configuration manager src/config/configuration.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH\n",
    "from src.utils.common import read_yaml, create_directories\n",
    "from src.logger import CustomLogger\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,logger: CustomLogger,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "        \n",
    "        self.logger = logger\n",
    "        self.config = read_yaml(config_filepath, logger=self.logger)\n",
    "        self.params = read_yaml(params_filepath, logger=self.logger)    \n",
    "\n",
    "        create_directories([self.config.model_artifacts_root], logger=self.logger)\n",
    "        \n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        training = self.config.training\n",
    "        prepare_base_model = self.config.prepare_base_model\n",
    "        \n",
    "        training_data = os.path.join(self.config.data_ingestion.unzip_dir, \"kidney-ct-scan-image\")\n",
    "        \n",
    "        create_directories([training.root_dir], logger=self.logger)\n",
    "        \n",
    "        prepare_training_model_config = TrainingConfig(\n",
    "            root_dir = Path(training.root_dir),\n",
    "            trained_model_path = Path(training.trained_model_path),\n",
    "            updated_base_model_path = Path(prepare_base_model.updated_base_model_path),\n",
    "            training_data = Path(training_data),\n",
    "            \n",
    "            params_augmentation = self.params.AUGMENTATION,\n",
    "            params_image_size = self.params.IMAGE_SIZE,\n",
    "            params_batch_size = self.params.BATCH_SIZE,\n",
    "            params_epochs = self.params.EPOCHS,\n",
    "            params_learning_rate = self.params.LEARNING_RATE,\n",
    "            params_activation=self.params.ACTIVATION\n",
    "        )\n",
    "        return prepare_training_model_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Update the components \\[data preprocessing, model training, and so on\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from src.logger import CustomLogger\n",
    "import math\n",
    "\n",
    "class Training:\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "        \n",
    "    def get_base_model(self, get_base_model_logger: CustomLogger):\n",
    "        try:\n",
    "            self.model = tf.keras.models.load_model(self.config.updated_base_model_path)\n",
    "            self.model.compile(\n",
    "                optimizer=tf.keras.optimizers.SGD(learning_rate=self.config.params_learning_rate),\n",
    "                loss=\"categorical_crossentropy\",\n",
    "                metrics=[\"accuracy\"]\n",
    "                )\n",
    "\n",
    "            \n",
    "            get_base_model_logger.save_logs(msg=f\"Model loaded from {self.config.updated_base_model_path} successfully.\", log_level=\"info\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            get_base_model_logger.save_logs(msg=f\"Error loading model from {self.config.updated_base_model_path}. Error: {str(e)}\", log_level=\"error\")\n",
    "            raise e\n",
    "        \n",
    "    def train_valid_generator(self, train_valid_generator_logger: CustomLogger):\n",
    "    \n",
    "        try:\n",
    "            \n",
    "            \n",
    "            ########## kwargs start ########## \n",
    "            \n",
    "            datagenerator_kwargs = dict(\n",
    "                rescale=1./255,\n",
    "                validation_split=0.2\n",
    "            )\n",
    "            \n",
    "            dataflow_kwargs = dict(\n",
    "                target_size = self.config.params_image_size[:-1],\n",
    "                batch_size = self.config.params_batch_size,\n",
    "                interpolation = \"bilinear\"\n",
    "            )\n",
    "            \n",
    "            val_specific_kwargs = dict(\n",
    "                directory = self.config.training_data,\n",
    "                subset=\"validation\",\n",
    "                shuffle = False,\n",
    "                class_mode = \"categorical\"\n",
    "            )\n",
    "            \n",
    "            train_specific_kwargs = dict(\n",
    "                directory = self.config.training_data,\n",
    "                subset = \"training\",\n",
    "                shuffle = True,\n",
    "                class_mode = \"categorical\"\n",
    "            )\n",
    "            \n",
    "            augmentation_kwargs = dict(\n",
    "                rotation_range=40,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                horizontal_flip=True)\n",
    "            \n",
    "            ########## kwargs end ########## \n",
    "            \n",
    "\n",
    "                    \n",
    "            ########## validation datagenerator start ########## \n",
    "            valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(**datagenerator_kwargs)\n",
    "            \n",
    "            self.valid_generator = valid_datagenerator.flow_from_directory(\n",
    "                **val_specific_kwargs,\n",
    "                **dataflow_kwargs\n",
    "            )\n",
    "            \n",
    "            train_valid_generator_logger.save_logs(msg=f\"Generated Validation generator successfully with these \\ndatagenerator_kwargs: {datagenerator_kwargs},\\ndataflow_kwargs: {val_specific_kwargs, dataflow_kwargs}\", log_level='info')\n",
    "            \n",
    "            ########## validation datagenerator end ##########\n",
    "            \n",
    "            ########## training datagenerator start ##########\n",
    "            if self.config.params_augmentation:\n",
    "                train_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(**augmentation_kwargs, **datagenerator_kwargs)\n",
    "                \n",
    "\n",
    "            else:\n",
    "                train_datagenerator = valid_datagenerator\n",
    "                \n",
    "            self.train_generator = train_datagenerator.flow_from_directory(\n",
    "                **train_specific_kwargs,\n",
    "                **dataflow_kwargs\n",
    "                )\n",
    "            \n",
    "            if self.config.params_augmentation:\n",
    "                train_valid_generator_logger.save_logs(msg=f\"Generated Train generator with AUGMENTATION: True successfully with these \\naugmentation_kwargs: {augmentation_kwargs},\\ndatagenerator_kwargs: {datagenerator_kwargs}, \\ndataflow_kwargs: {train_specific_kwargs, dataflow_kwargs}\", log_level='info')\n",
    "            else:\n",
    "                train_valid_generator_logger.save_logs(msg=f\"Generated Train generator with AUGMENTATION: False successfully with these \\ndatagenerator_kwargs: {datagenerator_kwargs}, \\ndataflow_kwargs: {train_specific_kwargs, dataflow_kwargs}\", log_level='info')\n",
    "            \n",
    "            ########## training datagenerator end ##########\n",
    "        except Exception as e:\n",
    "            train_valid_generator_logger.save_logs(msg=f\"Error in creating train and validation Generators. Error: {e}\",log_level=\"error\")\n",
    "            raise e\n",
    "\n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model, logger: CustomLogger):\n",
    "        try:\n",
    "            model.save(path)\n",
    "            logger.save_logs(msg=f\"Model saved at {path} successfully\", log_level=\"info\")\n",
    "        except Exception as e:\n",
    "            logger.save_logs(msg=f\"Error in saving model at {path}. Error: {e}\", log_level=\"error\")\n",
    "            raise e\n",
    "        \n",
    "        \n",
    "    def train(self, train_logger: CustomLogger, callback_list: list = None):\n",
    "        self.steps_per_epoch = math.ceil(self.train_generator.samples // self.train_generator.batch_size)\n",
    "        self.validation_steps = math.ceil(self.valid_generator.samples // self.valid_generator.batch_size)\n",
    "        try:\n",
    "            self.model.fit(\n",
    "                self.train_generator,\n",
    "                epochs=self.config.params_epochs,\n",
    "                steps_per_epoch=self.steps_per_epoch,\n",
    "                validation_steps=self.validation_steps,\n",
    "                validation_data=self.valid_generator,\n",
    "                callbacks=callback_list\n",
    "            )\n",
    "            train_logger.save_logs(msg=\"model.fit successfully\",log_level=\"info\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            train_logger.save_logs(msg=f\"Error in model.fit. Error: {e}\",log_level=\"error\")     \n",
    "            raise e       \n",
    "        \n",
    "        self.save_model(path=self.config.trained_model_path, model=self.model, logger=train_logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Update the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:configuration:yaml file: config\\config.yaml loaded successfully\n",
      "INFO:configuration:yaml file: params.yaml loaded successfully\n",
      "INFO:configuration:created directory at: models\n",
      "INFO:configuration:created directory at: models/training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager Execution: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:get_base_model:Model loaded from models\\prepare_base_model\\base_model_updated.h5 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 93 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train_valid_generator:Generated Validation generator successfully with these \n",
      "datagenerator_kwargs: {'rescale': 0.00392156862745098, 'validation_split': 0.2},\n",
      "dataflow_kwargs: ({'directory': WindowsPath('data/raw/kidney-ct-scan-image'), 'subset': 'validation', 'shuffle': False, 'class_mode': 'categorical'}, {'target_size': [224, 224], 'batch_size': 32, 'interpolation': 'bilinear'})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 372 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train_valid_generator:Generated Train generator with AUGMENTATION: True successfully with these \n",
      "augmentation_kwargs: {'rotation_range': 40, 'width_shift_range': 0.2, 'height_shift_range': 0.2, 'shear_range': 0.2, 'zoom_range': 0.2, 'horizontal_flip': True},\n",
      "datagenerator_kwargs: {'rescale': 0.00392156862745098, 'validation_split': 0.2}, \n",
      "dataflow_kwargs: ({'directory': WindowsPath('data/raw/kidney-ct-scan-image'), 'subset': 'training', 'shuffle': True, 'class_mode': 'categorical'}, {'target_size': [224, 224], 'batch_size': 32, 'interpolation': 'bilinear'})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - accuracy: 0.5668 - loss: 2.7622 \n",
      "Epoch 1: val_loss improved from inf to 0.63150, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 19s/step - accuracy: 0.5718 - loss: 2.6938 - val_accuracy: 0.8750 - val_loss: 0.6315 - learning_rate: 0.0100\n",
      "Epoch 2/2\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:15\u001b[0m 20s/step - accuracy: 0.8750 - loss: 0.5125\n",
      "Epoch 2: val_loss did not improve from 0.63150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.8750 - loss: 0.5125 - val_accuracy: 0.3281 - val_loss: 0.7024 - learning_rate: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:model.fit successfully\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "INFO:train:Model saved at models\\training\\model.h5 successfully\n"
     ]
    }
   ],
   "source": [
    "from src.logger import create_log_path, CustomLogger\n",
    "import logging\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "# path to save the log files\n",
    "get_base_model_log_file_path = create_log_path(\"training/get_base_model\")\n",
    "get_base_model_logger = CustomLogger(logger_name=\"get_base_model\", log_filename=get_base_model_log_file_path)\n",
    "get_base_model_logger.set_log_level(level=logging.INFO)\n",
    "\n",
    "\n",
    "train_valid_generator_log_file_path = create_log_path(\"training/train_valid_generator\")\n",
    "train_valid_generator_logger = CustomLogger(logger_name=\"train_valid_generator\", log_filename=train_valid_generator_log_file_path)\n",
    "train_valid_generator_logger.set_log_level(level=logging.INFO)\n",
    "\n",
    "\n",
    "\n",
    "train_log_file_path = create_log_path(\"training/train\")\n",
    "train_logger = CustomLogger(logger_name=\"train\", log_filename=train_log_file_path)\n",
    "train_logger.set_log_level(level=logging.INFO)\n",
    "\n",
    "configuration_log_file_path = create_log_path(\"configuration\")\n",
    "configuration_logger = CustomLogger(logger_name=\"configuration\", log_filename=configuration_log_file_path)\n",
    "configuration_logger.set_log_level(level=logging.INFO)\n",
    "\n",
    "\n",
    "############################## ERROR CORRECTION START ##########################\n",
    "tf.config.run_functions_eagerly(True)\n",
    "print(\"Eager Execution:\", tf.executing_eagerly())  # Check if enabled\n",
    "\n",
    "\n",
    "############## callbacks start ################\n",
    "# Callbacks\n",
    "# Early Stopping\n",
    "log_dir = \"logs\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Learning Rate Scheduler\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1).numpy()\n",
    "\n",
    "lr_scheduler = callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "# Model Checkpoint\n",
    "model_checkpoint = callbacks.ModelCheckpoint(\n",
    "    'best_model.h5', monitor='val_loss', save_best_only=True, verbose=1\n",
    ")\n",
    "\n",
    "# ReduceLROnPlateau\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1\n",
    ")\n",
    "\n",
    "# TensorBoard\n",
    "tensorboard = callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# TerminateOnNaN\n",
    "terminate_on_nan = callbacks.TerminateOnNaN()\n",
    "\n",
    "# ProgbarLogger\n",
    "progbar_logger = callbacks.ProgbarLogger()\n",
    "\n",
    "# CSV Logger\n",
    "csv_logger = callbacks.CSVLogger('training_log.csv', append=True)\n",
    "\n",
    "\n",
    "\n",
    "callbacks_list = [\n",
    "    early_stopping,\n",
    "    lr_scheduler,\n",
    "    model_checkpoint,\n",
    "    reduce_lr,\n",
    "    tensorboard,\n",
    "    terminate_on_nan,\n",
    "    #progbar_logger,\n",
    "    csv_logger\n",
    "]\n",
    "\n",
    "############## callbacks end ################\n",
    "\n",
    "try:\n",
    "    config = ConfigurationManager(configuration_logger)\n",
    "    training_config = config.get_training_config()\n",
    "    \n",
    "    training = Training(config=training_config)\n",
    "    training.get_base_model(get_base_model_logger=get_base_model_logger)\n",
    "    training.train_valid_generator(train_valid_generator_logger=train_valid_generator_logger)\n",
    "    training.train(train_logger=train_logger, callback_list=callbacks_list)\n",
    "    \n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.19.0'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Update the main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Update the dvc.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. app.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
